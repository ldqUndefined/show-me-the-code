# 极客时间-透视HTTP协议：重点总结

## 一、 http报文

http是一个**纯文本**协议，所以头数据都是ASCII码的文本，可以很容易地用肉眼阅读，不用借助程序解析也能够看懂。

http协议规定报文必须有header，但可以没有body，而且在header之后必须要有一个**“空行”**，也就是**"CRLF"**，十六进制的**"0D0A"**，如果header中的头部字段后多加了一个**CRLF**，会导致后面的头部字段被当做body处理。

### 1. 头部字段

- 字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好；
- 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名；
- 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格；但一般都只用一个空格，因为可以减小头部大小
- 字段的顺序是没有意义的，可以任意排列不影响语义；
- 字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。
- Host是请求字段，也是**唯一一个** HTTP/1.1 规范里要求必须出现的字段，也就是说，如果请求头里没有 Host，那这就是一个错误的报文。
- Content-Length，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。

## 2. URI

URI最后可以有**片段标识符"#fragment"**，它是URI所定位的资源内部的一个“锚点”或者“标签”，浏览器可以在获取资源后直接跳转到它只是的位置。但片段标识符仅能由浏览器这样的客户端使用，服务器是看不到的。也就是说，浏览器永远不会把带“#fragment”的 URI 发送给服务器，服务器也永远不会用这种方式去处理资源的片段。

URI里只能使用ASCII码，如果要在URI里使用英语以外的汉语、日语等，或者某些特殊的URI，会在path、query里出现“@&？“等起界定符作用的字符，会导致URI解析错误，所以**URI引入了编码机制**，对于 ASCII 码以外的字符集和特殊字符做一个特殊的操作，把它们转换成与 URI 语义不冲突的形式。这在 RFC 规范里称为“escape”和“unescape”，俗称“转义”。URI 转义的规则有点“简单粗暴”，直接把非 ASCII 码或特殊字符转换成十六进制字节值，然后前面再加上一个“%”。例如，空格被转义成“%20”，“?”被转义成“%3F”。而中文、日文等则通常使用 UTF-8 编码后再转义，例如“银河”会被转义成“%E9%93%B6%E6%B2%B3”。有了这个编码规则后，URI 就更加完美了，可以支持任意的字符集用任何语言来标记资源。不过我们在浏览器的地址栏里通常是不会看到这些转义后的“乱码”的，这实际上是浏览器一种“友好”表现，隐藏了 URI 编码后的“丑陋一面”。



## 二、http的特点

- HTTP 是灵活可扩展的，可以任意添加头字段实现任意功能；
- HTTP 是可靠传输协议，基于 TCP/IP 协议“尽量”保证数据的送达；
- HTTP 是应用层协议，比 FTP、SSH 等更通用功能更多，能够传输任意数据；
- HTTP 使用了请求 - 应答模式，客户端主动发起请求，服务器被动回复请求；
- HTTP 本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。

## 三、http实体数据

### 1. 数据类型与编码

HTTP借鉴了电子邮件系统里让电子邮件可以发送ASCII码以外的任意数据的方案：**“多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 MIME。**

MIME 是一个很大的标准规范，但 HTTP 只“顺手牵羊”取了其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的“MIME type”。

MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type/subtype”的字符串，刚好也符合了 HTTP 明文的特点，所以能够很容易地纳入 HTTP 头字段里。

HTTP里经常遇到的几个类别：

- text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。
- image：即图像文件，有 image/gif、image/jpeg、image/png 等。
- audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
- application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，也就是“黑盒”数据类型，就会是 application/octet-stream，即不透明的二进制数据。

有了MIME还不够，HTTP传输时为了节省带宽，有事还会压缩数据，所以还有了**“Encoding type”**，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

- gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
- deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
- br：一种专门为 HTTP 优化的新压缩算法（Brotli）。

### 2. 数据类型使用的头字段

HTTP 协议定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”。也就是说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。

**Accept** 字段标记的是客户端可理解的 MIME type，可以用“,”做分隔符列出多个类型：

`Accept: text/html,application/xml,image/webp,image/png`

服务器会在响应报文里用头字段 **Content-Type** 告诉实体数据的真实类型：

`Content-Type: text/html`

**Accept-Encoding** 字段标记的是客户端支持的压缩格式。

服务器可以选择一种压缩方式来压缩数据，实际使用的压缩格式放在响应头字段 **Content-Encoding** 里。

**Accept-Encoding** 和**Content-Encoding**这两个字段是可以省略的，如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩。

### 3. 语言类型与编码

MIME type 和 Encoding type 解决了计算机理解 body 数据的问题，但没有解决语言问题。因此引入了**语言类型与字符集**两个概念。

**“语言类型”**就是人类使用的自然语言，例如英语、汉语、日语等，而这些自然语言可能还有下属的地区性方言，所以在需要明确区分的时候也要使用“type-subtype”的形式，不过这里的格式与数据类型不同，**分隔符不是“/”，而是“-”**。

自然语言的计算机处理叫做**字符集**。

**Accept-Language** 字段标记了客户端可理解的自然语言，也允许用“,”做分隔符列出多个类型。

服务器应该在响应报文里用头字段 **Content-Language** 告诉客户端实体数据使用的实际语言类型。

字符集在 HTTP 里使用的请求头字段是 **Accept-Charset**，但响应头里却没有对应的 Content-Charset，而是在 Content-Type 字段的数据类型后面用“charset=xxx”来表示，这点需要特别注意：

`Accept-Charset: gbk, utf-8`

`Content-Type: text/html; charset=utf-8`

### 4. 内容协商的质量值

在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，还可以用一种特殊的“q”参数表示权重来设定优先级，这里的“q”是“quality factor”的意思。

权重的最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个“;”，然后是“q=value”。

这里要提醒的是“;”的用法，在大多数编程语言里“;”的断句语气要强于“,”，而在 HTTP 的内容协商里却恰好反了过来，“;”的意义是小于“,”的。如：

`Accept: text/html,application/xml;q=0.9,*/*;q=0.8`

### 5. 内容协商的结果

内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个 Vary 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：

`Vary: Accept-Encoding,User-Agent,Accept`

这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文。

## 四、HTTP传输大文件的方法

### 1. 数据压缩

通常浏览器在发送请求时都会带着**“Accept-Encoding”**头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进**“Content-Encoding”**响应头里，再把原数据压缩后发给浏览器。

不过这个解决方法也有个缺点，gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了。所以一般不对图片等多媒体进行压缩。

### 2. 分块传输

对于大文件的传输，除了数据压缩之外，还可以通过将它“拆分”成多个小块，然后分批发给浏览器，让浏览器收到后再组装复原。这样浏览器和服务器都不用在内存里保存文件的全部，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。

分块传输在响应报文中用头字段**Transfer-Encoding: chunked”**来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。**“Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked）**。

分块传输的编码规则很简单，使用明文的方式：

1. 每个分块包含两个部分，长度头和数据块；
2. 长度头是以 CRLF（回车换行，即\r\n）结尾的一行明文，用 16 进制数字表示长度；
3. 数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF；
4. 最后用一个长度为 0 的块表示结束，即“0\r\n\r\n”。

![分块传输](./图片/分块传输.png)

浏览器在收到分块传输的数据后会自动按照规则去掉分块编码，重新组装出内容，所以在浏览器中是看不出所谓的“分块传输”，仍然是一个相应报文。

### 3. 范围请求

想要获取一个大文件的其中的片段数据，如视频的特定时间范围内的数据，分块传输没有这个能力。

范围请求”（range requests）允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零”。范围请求不是 Web 服务器必备的功能，可以实现也可以不实现，所以服务器必须在响应头里使用字段**“Accept-Ranges: bytes”**明确告知客户端：“我是支持范围请求的”。如果不支持的话服务器可以发送**“Accept-Ranges: none”**，或者干脆不发送“Accept-Ranges”字段，这样客户端就认为服务器没有实现范围请求功能，只能老老实实地收发整块文件了。

请求头 **Range** 是 HTTP 范围请求的专用字段，格式是**“bytes=x-y”**，其中的 x 和 y 是以字节为单位的数据范围。x、y 表示的是“偏移量”，范围必须从 0 计数，例如前 10 个字节表示为“0-9”，第二个 10 字节表示为“10-19”，而“0-10”实际上是前 11 个字节。

`Range: bytes=0-199`

服务器收到 Range 字段后，需要做四件事：

1. 它必须检查范围是否合法，比如文件只有 100 个字节，但请求“200-300”，这就是范围越界了。服务器就会返回状态码 416，意思是“你的范围请求有误，我无法处理，请再检查一下”。
2. 如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码“206 Partial Content”，和 200 的意思差不多，但表示 body 只是原数据的一部分。
3. 服务器要添加一个响应头字段 **Content-Range**，告诉片段的实际偏移量和资源的总大小，格式是“**bytes x-y/length**”，与 Range 头区别在没有“=”，范围后多了总长度。例如，对于“0-10”的范围请求，值就是“bytes 0-10/100”。`Content-Range: bytes 0-19/100`

### 4. 多段数据

范围请求一次只获取一个片段，其实它还支持在 Range 头里使用多个“x-y”，一次性获取多个片段数据。

这种情况需要使用一种特殊的 MIME 类型：**“multipart/byteranges”**，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数**“boundary=xxx”**给出段之间的分隔标记。

多段数据的格式与分块传输也比较类似，但它需要用分隔标记 boundary 来区分不同的片段，可以通过图来对比一下：

![多段数据](./图片/多段数据.png)

每一个分段必须以**“- -boundary”**开始（前面加两个“-”），之后要用**“Content-Type”**和**“Content-Range”**标记这段数据的类型和所在范围，然后就像普通的响应头一样以回车换行结束，再加上分段数据，最后用一个**“- -boundary- -”**（前后各有两个“-”）表示所有的分段结束。

请求示例：

`GET /16-2 HTTP/1.1`
`Host: www.chrono.com`
`Range: bytes=0-9, 20-29`

响应示例：

`HTTP/1.1 206 Partial Content`
`Content-Type: multipart/byteranges; boundary=00000000001`
`Content-Length: 189`
`Connection: keep-alive`
`Accept-Ranges: bytes`

`--00000000001`
`Content-Type: text/plain`
`Content-Range: bytes 0-9/96`

`// this is`
`--00000000001`
`Content-Type: text/plain`
`Content-Range: bytes 20-29/96`

`ext json d`
`--00000000001--`

## 五、HTTP的连接管理

### 1. 短连接

HTTP(0.9/1.0)是个非常简单的协议，通信过程也采用了简单的“请求-应答”方式。底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“短连接”（short-lived connections）。早期的 HTTP 协议也被称为是“无连接”的协议。

短连接的缺点相当严重，因为在 TCP 协议里，**建立连接和关闭连接都是非常“昂贵”的操作**。TCP 建立连接要有**“三次握手”**，发送 **3** 个数据包，需要 **1(1.5)**个 RTT；关闭连接是**“四次挥手”**，**4** 个数据包需要 **2** 个 RTT。

(这里http请求和响应有4个数据包是因为，发送请求一个http请求是一个数据包，服务器返回一个tcp ack是一个数据包，服务器返回HTTP响应是一个数据包，客户端收到HTTP响应发送tcp ack一个数据包)

而 HTTP 的一次简单“请求 - 响应”通常只需要 **4** 个包，如果不算服务器内部的处理时间，最多是 **2** 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有**三分之二**的时间被浪费掉了，传输效率低得惊人。

### 2. 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了**“长连接”**的通信方式，也叫**“持久连接”（persistent connections）**、**“连接保活”（keep alive）**、**“连接复用”（connection reuse）**。

其实解决办法也很简单，用的就是**“成本均摊”**的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上。

这样虽然不能改善 TCP 的连接效率，但基于“分母效应”，每个“请求 - 应答”的无效时间就会降低不少，整体传输效率也就提高了。

![短连接和长连接](./图片/短连接和长连接.png)

**显然，如果在这个长连接上发送的请求越多，分母就越大，利用率也就越高。**

因为TCP协议还有**“慢启动”"拥塞窗口"**等特性，通常建立新的“冷连接”会比打开一段时间的“热连接”要慢一些，所以长连接比端连接还多了这一层的优势。

长连接的一个重要问题是如何正确地区分多个报文的开始和结束，所以最好总使用"content-length"头明确相应实体的长度，正确标记报文结束。如果是流式传输，body长度不能立即确定，就必须用分块传输编码。

利用HTTP的长连接特性对服务器发起大量请求，导致服务器最终耗尽资源“拒绝服务”，就是场所的DoS。

HTTP的连接管理还有第三种pipeline(管道，或者叫流水线)，在长连接的基础上又进了一步，可以批量发送请求批量接收响应，但因为存在一些问题，Chrome等浏览器都没有实现它，已经被事实上“废弃”了。

Connection字段还有一个取值：“onnection:Upgrade”，配合状态码101表示协议升级，例如从HTTP切换到WebSocket。

### 3. 连接相关的头字段

由于长连接对性能的改善效果非常显著，所以在 HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。也可以在请求头里明确地要求使用长连接机制，使用的字段是 Connection，值是“keep-alive”。不管客户端是否显式要求长连接，如果服务器支持长连接，它总会在响应报文里放一个“Connection: keep-alive”字段，告诉客户端：“我是支持长连接的，接下来就用这个 TCP 一直收发数据吧”。

**不过长连接也有一些小缺点，问题就出在它的“长”字上。**

因为 TCP 连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。

所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。

在客户端，可以在请求头里加上“Connection: close”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。

**服务器端通常不会主动关闭连接，但也可以使用一些策略**。拿 Nginx 来举例，它有两种方式：

- 使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
- 使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

另外，客户端和服务器都可以在报文里附加通用头字段“Keep-Alive: timeout=value”，限定长连接的超时时间。**但这个字段的约束力并不强，通信的双方可能并不会遵守，所以不太常见。**

### 4. 队头阻塞

**对头阻塞(Head-of-line blocking)与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。**

因为 HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。

如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。

![队头阻塞](./图片/队头阻塞.png)

队头阻塞在http和tcp层次都有，原因不同。这里将的是http队头阻塞。

### 5. 性能优化

“请求 - 应答”模型不能变，所以**“队头阻塞”问题在 HTTP/1.1 里无法解决，只能缓解**。

可以采用**“并发连接”（concurrent connections）**，**也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。**

但这种方式**也存在缺陷**。如果每个客户端都想自己快，建立很多个连接，用户数×并发数就会是个天文数字。服务器的资源根本就扛不住，或者被服务器认为是恶意攻击，反而会造成“拒绝服务”。

所以，HTTP 协议建议客户端使用并发，但不能“滥用”并发。RFC2616 里明确限制每个客户端最多并发 2 个连接。不过实践证明这个数字实在是太小了，众多浏览器都“无视”标准，把这个上限提高到了 **6~8**。后来修订的 RFC7230 也就“顺水推舟”，取消了这个“2”的限制。

但是，如果"并发连接"锁压榨出的性能还是无法满足需求，还有什么办法？还可以使用“域名分片”。

**“域名分片”（domain sharding）技术，还是用数量来解决质量的思路。**

**HTTP 协议和浏览器限制对同一个域名的并发连接数量**，那我们可以通过多开几个域名绕过这个限制。比如 shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器 www.chrono.com，这样实际长连接的数量又翻了一倍。



## 六、HTTP重定向和跳转

在浏览器上点击链接跳转时，浏览器会解析链接里的URI，再用这个URI发起一个新的HTTP请求，获取响应报文后会渲染出新URI指向的页面，这样的跳转是由浏览器的使用者主动发起的，可以称为“主动跳转”，但还有一类跳转是由服务器发起的，浏览器无法控制，相对地称为“被动跳转”，这在HTTP协议里有个专门的名词，叫做**“重定向”(Redirection)**。

### 1. 重定向的过程

当发送的HTTP请求获得的HTTP响应中带有301、302等代表跳转的状态码时，浏览器会重定向到响应报文中Location指定的资源，不用开发者工具的话是看不到这个跳转过程的，也就是重定向是“用户无感知”的。

**“Location”**字段属于响应字段，**只能出现在响应报文里**。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI，要求浏览器跳转到指定的资源。

浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接。

在“Location”里的 URI **既可以使用绝对 URI，也可以使用相对 URI**。所谓“绝对 URI”，就是完整形式的 URI，包括 scheme、host:port、path 等。所谓“相对 URI”，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到。

### 2. 重定向状态码

- 301俗称“永久重定向”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。
- 302 俗称“临时重定向”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI。
- 303 See Other：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作；（理解为有限制的302）
- 307 Temporary Redirect：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确；（也可以理解为有限制的302）
- 308 Permanent Redirect：类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义。（理解为有限制的301？）

**303、307、308三个状态码的接受程度较低，有的浏览器和服务器可能不支持，开发时应当慎重，测试确认浏览器的实际效果后才能使用。**

### 3. 重定向的应用场景

使用3xx状态码**可以在服务端拥有主动权**，控制浏览器的行为。

使用重定向跳转，核心是要理解**“重定向”**和**“永久 / 临时”**这两个关键词。

重定向的使用场景：

- 一个最常见的原因就是“资源不可用”，需要用另一个新的 URI 来代替。至于不可用的原因那就很多了。例如域名变更、服务器变更、网站改版、系统维护，这些都会导致原 URI 指向的资源无法访问，为了避免出现 404，就需要用重定向跳转到新的 URI，继续为网民提供服务。
- 另一个原因就是“避免重复”，让多个网址都跳转到一个 URI，增加访问入口的同时还不会增加额外的工作量。例如，有的网站都会申请多个名称类似的域名，然后把它们再重定向到主站上。

决定要实行重定向后接下来要考虑的就是“永久”和“临时”的问题了，也就是选择 301 还是 302：

- 301 的含义是“永久”的。

  如果域名、服务器、网站架构发生了大幅度的改变，比如启用了新域名、服务器切换到了新机房、网站目录层次重构，这些都算是“永久性”的改变。原来的 URI 已经不能用了，必须用 301“永久重定向”，通知浏览器和搜索引擎更新到新地址，这也是搜索引擎优化（SEO）要考虑的因素之一。

- 302 的含义是“临时”的。

  原来的 URI 在将来的某个时间点还会恢复正常，常见的应用场景就是系统维护，把网站重定向到一个通知页面，告诉用户过一会儿再来访问。另一种用法就是“服务降级”，比如在双十一促销的时候，把订单查询、领积分等不重要的功能入口暂时关闭，保证核心服务能够正常运行。

### 4. 重定向相关问题

- 性能损耗

  很明显，重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次。虽然 301/302 报文很小，但大量的跳转对服务器的影响也是不可忽视的。站内重定向还好说，可以长连接复用，站外重定向就要开两个连接，如果网络连接质量差，那成本可就高多了，会严重影响用户的体验。所以重定向应当适度使用，决不能滥用。

- 循环跳转

  如果重定向的策略设置欠考虑，可能会出现“A=>B=>C=>A”的无限循环，不停地在这个链路里转圈圈。所以 HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力，在发现这种情况时应当停止发送请求并给出错误提示。

重定向报文里还可以用Refresh字段，实现延时重定向，例如"Refresh: 5； url=xxx"告诉浏览器5秒后再跳转。

与跳转有关的还有一个"Referer"和"Referrer-Policy"，表示浏览器的来源(即引用地址)，可用于统计分析和防盗链。

301/302重定向是由浏览器执行的，对于服务器来说可以称为**"外部重定向"**,相应的也就有服务器的**“内部重定向”**，直接在服务器内部跳转URI，因为不会发出额外的HTTP请求，(即在相应报文里就带回了新URI)，所以没有额外的性能损失。



## 七、HTTP的Cookie机制

HTTP 是**“无状态”**的，这既是优点也是缺点。优点是服务器没有状态差异，可以很容易地组成集群，而缺点就是无法支持需要记录状态的事务操作。好在 **HTTP 协议是可扩展的**，后来发明的 Cookie 技术，给 HTTP 增加了“记忆能力”。

### 1. Cookie 的工作过程

要用到两个字段：响应头字段 **Set-Cookie** 和请求头字段 **Cookie**。

服务器通过在响应报文里添加Set-Cookie字段，以key=value的键值对形式发送给浏览器，浏览器收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。服务器有时会在响应头里添加多个 Set-Cookie，存储多个“key=value”。但浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用“;”隔开就行。

**Cookie 是由浏览器负责存储的**，而不是操作系统。所以，它是“浏览器绑定”的，只能在本浏览器内生效。

### 2. Cookie的属性

- Cookie 的生存周期

  Cookie 的生存周期，也就是它的有效期，让它只能在一段时间内可用，就像是食品的“保鲜期”，一旦超过这个期限浏览器就认为是 Cookie 失效，在存储里删除，也不会发送给服务器。

  Cookie 的有效期可以使用 Expires 和 Max-Age 两个属性来设置。

  **“Expires”**俗称“过期时间”，用的是**绝对时间点**，可以理解为“截止日期”（deadline）。**“Max-Age”**用的是**相对时间**，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间。

  Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，但**浏览器会优先采用 Max-Age 计算失效期**。

  如果不指定Expires或Max-Age属性，那么Cookie仅在浏览器运行时有效，一旦浏览器关闭就会失效，这被称为会话Cookie(session cookie)或内存Cookie(in-memory cookie)。

  如果Cookie的Max-age设置为0，就是立即过期，不允许缓存，但在会话期间是可用的，浏览器会话关闭之前可用cookie记录用户的信息。

- Cookie 的作用域

  Cookie 的作用域，让浏览器仅发送给特定的服务器和 URI，避免被其他网站盗用。作用域的设置比较简单，**“Domain”**和**“Path”**指定了 Cookie 所属的**域名**和**路径**，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。

  现实中为了省事，通常 Path 就用一个“/”或者直接省略，表示域名下的任意路径都允许使用 Cookie，让服务器自己去挑。

  `Domain` 指定了哪些主机可以接受 Cookie。如果不指定，默认为 origin，**不包含子域名**。如果指定了`Domain`，则一般包含子域名。因此，指定 `Domain` 比省略它的限制要少。但是，当子域需要共享有关用户的信息时，这可能会有所帮助。 

- Cookie 的安全性

  在前端在JS 脚本里可以用 **document.cookie** 来读写 Cookie 数据，这就带来了安全隐患，有可能会导致“跨站脚本”（XSS）攻击窃取数据。

  属性**“HttpOnly”**会告诉浏览器，**此 Cookie 只能通过浏览器 HTTP 协议传输，禁止其他方式访问**，浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API，脚本攻击也就无从谈起了。

  另一个属性**“SameSite”**可以防范“跨站请求伪造”（XSRF）攻击，设置成**“SameSite=Strict”**可以严格限定 Cookie 不能随着跳转链接跨站发送，而**“SameSite=Lax”**则略宽松一点，允许 GET/HEAD 等安全方法，但禁止 POST 跨站发送。设置**“SameSite=None”**的前提是同时设置`Secure`属性（Cookie 只能通过 HTTPS 协议发送），否则无效。

  还有一个属性叫**“Secure”**，表示这个 Cookie **仅能用 HTTPS 协议加密传输**，明文的 HTTP 协议会禁止发送。但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在。新版本的浏览器中，HTTP:无法使用Cookie的Secure标记。

  这个链接将sameSite讲得很好：[sameSite用法](https://www.ruanyifeng.com/blog/2019/09/cookie-samesite.html)


浏览器对Cookie的大小有限制，不允许无限存储，一般总大小不能超过4KB。



### 3. Cookie的应用

- 身份识别

  Cookie 最基本的一个用途就是身份识别，保存用户的登录信息，实现会话事务。

  比如，你用账号和密码登录某电商，登录成功后网站服务器就会发给浏览器一个 Cookie，内容大概是“name=yourid”，这样就成功地把身份标签贴在了你身上。之后你在网站里随便访问哪件商品的页面，浏览器都会自动把身份 Cookie 发给服务器，所以服务器总会知道你的身份，一方面免去了重复登录的麻烦，另一方面也能够自动记录你的浏览记录和购物下单（在后台数据库或者也用 Cookie），实现了“状态保持”。

- 广告跟踪

  Cookie 的另一个常见用途是广告跟踪。

  你上网的时候肯定看过很多的广告图片，这些图片背后都是广告商网站（例如 Google），它会“偷偷地”给你贴上 Cookie 小纸条，这样你上其他的网站，别的广告就能用 Cookie 读出你的身份，然后做行为分析，再推给你广告。

  这种 Cookie 不是由访问的主站存储的，所以又叫“第三方 Cookie”（third-party cookie）。如果广告商势力很大，广告到处都是，那么就比较“恐怖”了，无论你走到哪里它都会通过 Cookie 认出你来，实现广告“精准打击”。




















